\documentclass[10pt]{article}

\usepackage[utf8]{inputenc}
\usepackage[spanish]{babel}
\decimalpoint
\usepackage{amsmath, amssymb}
\usepackage{xcolor}
\usepackage{geometry}
\geometry{letterpaper, margin=1in}
\usepackage{graphicx}
\usepackage{float}
\usepackage{array}
\usepackage{booktabs}
\usepackage{colortbl}
\usepackage{caption}
\usepackage{tocloft}

\usepackage[colorlinks=true, linkcolor=black, urlcolor=black, citecolor=black]{hyperref}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% DOCUMENT METADATA
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\title{Universidad Panamericana \\ 
    Maestría en Ciencia de Datos \\ 
    Datos Masivos \\ 
    \vspace{0.5cm} 
    Proyecto Final: \textit{Pipeline Distribuido de Predicción para Iowa Liquor Sales en GCP}}
\author{Enrique Ulises Báez Gómez Tagle, Luis Alejandro Guillén Alvarez}
\date{\today}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{document}

\maketitle
\tableofcontents
\newpage

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% 1. DATASET UTILIZADO
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Dataset utilizado}
\subsection{Fuente y descripción}

El dataset utilizado proviene de \textbf{BigQuery Public Data} y contiene registros de ventas de licores en el estado de Iowa, Estados Unidos. Este conjunto de datos es mantenido por el Iowa Department of Commerce y está disponible públicamente para análisis.

\begin{itemize}
  \item \textbf{Fuente:} BigQuery Public Data - \texttt{bigquery-public-data.iowa\_liquor\_sales.sales}
  \item \textbf{Tamaño:} 32,816,143 registros
  \item \textbf{Periodo:} 2012-01-03 a 2025-10-31 (13.8 años)
  \item \textbf{Características principales:}
  \begin{itemize}
    \item \texttt{date}: Fecha de la transacción
    \item \texttt{store\_number}: Identificador de la tienda
    \item \texttt{city}: Ciudad donde se realizó la venta
    \item \texttt{category}: Categoría del producto
    \item \texttt{item\_number}: Identificador del producto
    \item \texttt{sale\_dollars}: Monto de la venta (variable objetivo)
    \item \texttt{bottles\_sold}: Cantidad de botellas vendidas
    \item \texttt{volume\_sold\_liters}: Volumen vendido en litros
  \end{itemize}
\end{itemize}

\subsection{Cardinalidades y dimensiones}

El dataset presenta alta cardinalidad en múltiples dimensiones, lo que lo hace ideal para procesamiento distribuido:

\begin{table}[H]
  \centering
  \caption{Cardinalidades del dataset Iowa Liquor Sales.}
  \label{tab:cardinalities}
  \scriptsize
  \begin{tabular}{@{}lr@{}}
    \toprule
    Dimensión & Valores Únicos \\
    \midrule
    Tiendas & 3,337 \\
    Ciudades & 504 \\
    Productos & 15,183 \\
    Categorías & 185 \\
    \bottomrule
  \end{tabular}
\end{table}

\subsection{Calidad de los datos}

El análisis exploratorio reveló una excelente calidad de datos con mínimos valores faltantes:

\begin{table}[H]
  \centering
  \caption{Valores nulos por campo.}
  \label{tab:missing-values}
  \scriptsize
  \begin{tabular}{@{}lrr@{}}
    \toprule
    Campo & Valores Nulos & Porcentaje \\
    \midrule
    sale\_dollars & 10 & 0.00003\% \\
    category & 16,974 & 0.052\% \\
    city & 84,575 & 0.258\% \\
    \midrule
    \textbf{Total} & \textbf{101,559} & \textbf{0.31\%} \\
    \bottomrule
  \end{tabular}
\end{table}

\textbf{Calidad general:} 99.69\% de datos completos, lo que indica un dataset de alta calidad para modelado predictivo.

\subsection{Distribución de ventas}

La distribución de la variable objetivo (\texttt{sale\_dollars}) muestra las siguientes características:

\begin{table}[H]
  \centering
  \caption{Distribución de ventas en dólares.}
  \label{tab:sales-distribution}
  \scriptsize
  \begin{tabular}{@{}lr@{}}
    \toprule
    Percentil & Valor (USD) \\
    \midrule
    P50 (Mediana) & \$78.66 \\
    P90 & \$269.88 \\
    P99 & \$1,185.60 \\
    \bottomrule
  \end{tabular}
\end{table}

\subsection{Top 10 categorías por volumen de ventas}

Las categorías más vendidas representan una parte significativa del volumen total de transacciones:

\begin{table}[H]
  \centering
  \caption{Top 10 categorías por ventas totales.}
  \label{tab:top-categories}
  \scriptsize
  \begin{tabular}{@{}rlrr@{}}
    \toprule
    Rank & Categoría & Ventas Totales (USD) & Transacciones \\
    \midrule
    1 & 1012100.0 & \$495,078,200 & 2,778,490 \\
    2 & 1031100.0 & \$441,329,100 & 2,988,622 \\
    3 & 1011200.0 & \$288,427,900 & 1,859,256 \\
    4 & 1081600.0 & \$219,643,200 & 1,360,017 \\
    5 & 1062400.0 & \$169,326,700 & 861,360 \\
    6 & 1022200.0 & \$152,794,300 & 668,286 \\
    7 & 1031080.0 & \$145,760,500 & 1,265,930 \\
    8 & 1022100.0 & \$143,383,100 & 849,580 \\
    9 & 1011400.0 & \$119,534,300 & 538,956 \\
    10 & 1011100.0 & \$117,536,600 & 1,213,606 \\
    \midrule
    \textbf{Total Top 10} & & \textbf{\$2,292,813,900} & \textbf{15,384,103} \\
    \bottomrule
  \end{tabular}
\end{table}

\subsection{Justificación de selección}

Este dataset fue seleccionado por las siguientes razones:

\begin{enumerate}
  \item \textbf{Volumen masivo:} Con más de 32 millones de registros, cumple ampliamente con el requisito de $\geq$32M registros y justifica el uso de procesamiento distribuido con PySpark en Dataproc.
  
  \item \textbf{Datos temporales:} El rango de 13.8 años permite análisis de series temporales y patrones estacionales, ideal para feature engineering temporal.
  
  \item \textbf{Alta dimensionalidad:} La combinación de 15K+ productos, 185 categorías, 3.3K tiendas y 504 ciudades proporciona un espacio de características rico para modelado predictivo.
  
  \item \textbf{Calidad excepcional:} Con 99.69\% de datos completos, minimiza la necesidad de imputación compleja y permite enfocarse en transformaciones y modelado.
  
  \item \textbf{Variable objetivo continua:} \texttt{sale\_dollars} es una variable continua ideal para regresión lineal, permitiendo predecir montos de venta basados en características de productos, ubicación y temporalidad.
  
  \item \textbf{Disponibilidad pública:} Al estar en BigQuery Public Data, facilita la reproducibilidad del proyecto y el acceso sin restricciones de licenciamiento.
  
  \item \textbf{Relevancia práctica:} Los modelos predictivos de ventas tienen aplicaciones directas en optimización de inventario, planificación de demanda y estrategias de pricing.
\end{enumerate}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% 2. ARQUITECTURA IMPLEMENTADA
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Descripción de la arquitectura implementada}

\subsection{Diagrama de arquitectura}

La arquitectura implementada sigue un patrón de medallion con dos capas (Bronze y Gold) sobre Google Cloud Platform, integrando servicios de almacenamiento, procesamiento distribuido y análisis de datos masivos.

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{../figures/architecture/iowa-liquor-sales-ml-pipeline-architecture.png}
    \caption{Arquitectura del pipeline distribuido: BigQuery → Cloud Run → GCS Bronze → Dataproc → GCS Gold → ML Model.}
    \label{fig:architecture}
\end{figure}

\subsection{Flujo de datos}

El pipeline implementa un flujo de datos end-to-end con las siguientes etapas:

\begin{enumerate}
  \item \textbf{Fuente de datos (BigQuery):} El dataset público \texttt{iowa\_liquor\_sales} (32M+ registros) sirve como origen de datos. Los scripts de EDA (\texttt{eda\_iowa.py} y \texttt{eda\_iowa.ipynb}) realizan análisis exploratorio inicial directamente sobre BigQuery.
  
  \item \textbf{Extracción (Cloud Run):} Un servicio ETL desplegado en Cloud Run ejecuta \texttt{bronze\_extract.py}, que extrae datos desde BigQuery y los carga en formato Parquet particionado hacia la capa Bronze en Google Cloud Storage.
  
  \item \textbf{Capa Bronze (GCS):} Almacenamiento de datos crudos en formato Parquet con particionamiento temporal, preservando la estructura original para trazabilidad y reproducibilidad.
  
  \item \textbf{Transformación (Dataproc):} Un cluster de Dataproc ejecuta \texttt{gold\_transform.py} con PySpark, aplicando limpieza, transformaciones y feature engineering sobre los datos Bronze. El procesamiento distribuido permite manejar el volumen masivo de forma eficiente.
  
  \item \textbf{Capa Gold (GCS):} Datos limpios, transformados y enriquecidos con features derivadas, almacenados en formato Parquet particionado y optimizados para consumo analítico y modelado ML.
  
  \item \textbf{Modelado ML:} Modelo de regresión lineal con PySpark MLlib entrenado sobre la capa Gold para predicción de ventas, con evaluación de métricas (R², RMSE, MAE) y comparación de performance entre configuraciones de cluster.
\end{enumerate}

\subsection{Componentes de la arquitectura}

\begin{itemize}
  \item \textbf{BigQuery:} Fuente de datos pública (\texttt{bigquery-public-data.iowa\_liquor\_sales.sales})
  \item \textbf{Cloud Run:} Servicio ETL serverless para extracción batch hacia capa Bronze
  \item \textbf{GCS Bronze Layer:} Almacenamiento de datos crudos en formato Parquet particionado
  \item \textbf{Dataproc (PySpark):} Cluster de procesamiento distribuido para transformación y feature engineering
  \item \textbf{GCS Gold Layer:} Datos refinados listos para análisis y modelado
  \item \textbf{Terraform:} Infraestructura como código para provisionar clusters Dataproc con diferentes configuraciones
  \item \textbf{ML Model:} Modelo de regresión PySpark MLlib para predicción de ventas
\end{itemize}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% 3. DESARROLLO DE LA RUTA ELEGIDA
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Desarrollo de la ruta elegida: Procesamiento Distribuido con PySpark}

\subsection{Selección y exportación del dataset hacia GCS}

\subsubsection{Proceso de exportación}

La extracción de datos desde BigQuery hacia Google Cloud Storage se implementó mediante un servicio ETL desplegado en Cloud Run, diseñado para ejecutarse como job batch serverless. El proceso consta de tres etapas principales:

\paragraph{Etapa 1: Creación de tabla temporal con particionamiento.}
El script \texttt{bronze\_extract.py} ejecuta una consulta SQL que selecciona todos los registros del dataset público y agrega columnas derivadas de año y mes para facilitar el particionamiento posterior en PySpark:

\begin{verbatim}
SELECT 
    *,
    EXTRACT(YEAR FROM date) as year,
    EXTRACT(MONTH FROM date) as month
FROM `bigquery-public-data.iowa_liquor_sales.sales`
\end{verbatim}

Esta consulta materializa una tabla temporal en el dataset \texttt{ml\_work.bronze\_temp} del proyecto, permitiendo una exportación eficiente sin modificar la fuente original.

\paragraph{Etapa 2: Exportación a formato Parquet.}
Utilizando la API de BigQuery, se exportan los datos desde la tabla temporal hacia Google Cloud Storage en formato Parquet, un formato columnar optimizado para procesamiento distribuido:

\begin{itemize}
  \item \textbf{Destino:} \texttt{gs://iowa-liquor-medallion-ml/bronze/iowa\_sales/*.parquet}
  \item \textbf{Formato:} Parquet (columnar, comprimido)
  \item \textbf{Particionamiento:} Múltiples archivos generados automáticamente por BigQuery
\end{itemize}

\paragraph{Etapa 3: Limpieza y registro de métricas.}
Una vez completada la exportación, se elimina la tabla temporal y se registran las métricas de tiempo en un archivo JSON almacenado en GCS para trazabilidad.

\subsubsection{Configuración de Cloud Run}

El servicio se despliega mediante un contenedor Docker con las siguientes características:

\begin{itemize}
  \item \textbf{Imagen base:} \texttt{python:3.11-slim}
  \item \textbf{Dependencias:} \texttt{google-cloud-bigquery}, \texttt{google-cloud-storage}, \texttt{pandas}, \texttt{pyarrow}, \texttt{db-dtypes}
  \item \textbf{Tipo de ejecución:} Cloud Run Job (batch, no HTTP)
  \item \textbf{Variables de entorno:}
  \begin{itemize}
    \item \texttt{PROJECT\_ID}: \texttt{secure-cipher-475203-k2}
    \item \texttt{BUCKET\_NAME}: \texttt{iowa-liquor-medallion-ml}
  \end{itemize}
\end{itemize}

\begin{figure}[H]
  \centering
  \includegraphics[width=0.8\linewidth]{../img/cloud-run-images/cloudrun_job_execution_history_config.png}
  \caption{Configuración y historial de ejecución del Cloud Run Job para extracción Bronze.}
  \label{fig:cloudrun-config}
\end{figure}

\subsubsection{Métricas de tiempo de ejecución}

La fase de extracción Bronze completó exitosamente con las siguientes métricas:

\begin{table}[H]
  \centering
  \caption{Tiempos de ejecución de la fase Bronze (Cloud Run).}
  \label{tab:bronze-timing}
  \scriptsize
  \begin{tabular}{@{}lr@{}}
    \toprule
    Etapa & Tiempo \\
    \midrule
    Creación de tabla temporal & 5.51s \\
    Exportación a Parquet (GCS) & 2.81s \\
    Limpieza de recursos & 0.16s \\
    \midrule
    \textbf{Tiempo total} & \textbf{8.51s (0.14 min)} \\
    \bottomrule
  \end{tabular}
\end{table}

\begin{figure}[H]
  \centering
  \includegraphics[width=0.8\linewidth]{../img/cloud-run-images/cloudrun_observability_metrics.png}
  \caption{Métricas de observabilidad del Cloud Run Job mostrando ejecución exitosa.}
  \label{fig:cloudrun-metrics}
\end{figure}

\subsubsection{Verificación de estructura y consistencia}

Una vez completada la exportación, se verificó la estructura del bucket de GCS y la integridad de los datos:

\paragraph{Estructura del bucket.}
El bucket \texttt{iowa-liquor-medallion-ml} queda entonces con la siguiente carpeta:

\begin{itemize}
  \item \texttt{bronze/iowa\_sales/}: Datos crudos en formato Parquet (32,816,143 registros)
\end{itemize}

\paragraph{Archivos Parquet en capa Bronze.}
BigQuery generó múltiples archivos Parquet para optimizar la exportación paralela. Cada archivo contiene un subconjunto de los registros totales:

\begin{figure}[H]
  \centering
  \includegraphics[width=0.8\linewidth]{../img/cloud-storage-images/gcs_bronze_layer_parquet_files.png}
  \caption{Archivos Parquet en la capa Bronze listos para procesamiento distribuido.}
  \label{fig:gcs-bronze}
\end{figure}

\paragraph{Validaciones realizadas.}
\begin{itemize}
  \item \textbf{Conteo de registros:} 32,816,143 registros exportados (coincide con el dataset original)
  \item \textbf{Formato:} Parquet columnar con compresión Snappy
  \item \textbf{Esquema:} Todas las columnas originales + columnas derivadas \texttt{year} y \texttt{month}
  \item \textbf{Integridad:} Sin errores de exportación, todos los archivos accesibles
  \item \textbf{Trazabilidad:} Métricas de tiempo registradas en \texttt{job\_timing\_bronze.json}
\end{itemize}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Procesamiento distribuido en Dataproc}

\subsubsection{Configuración de clusters}

Se provisionaron dos configuraciones de clusters Dataproc mediante \textbf{infraestructura automatizada como código (Terraform)}, permitiendo despliegues reproducibles y parametrizables para evaluar el impacto del tamaño y tipo de máquina en el rendimiento del procesamiento distribuido:

\paragraph{Cluster 1: Configuración estándar (n1-standard).}
Cluster con perfil balanceado de CPU y memoria, optimizado para cargas de trabajo generales:

\begin{table}[H]
  \centering
  \caption{Configuración del Cluster 1 (n1-standard-3w).}
  \label{tab:cluster1-config}
  \scriptsize
  \begin{tabular}{@{}lll@{}}
    \toprule
    Componente & Tipo de Máquina & Recursos \\
    \midrule
    Master & n1-standard-2 & 2 vCPUs, 7.5 GB RAM \\
    Workers (3x) & n1-standard-2 & 2 vCPUs, 7.5 GB RAM (cada uno) \\
    \midrule
    \textbf{Total} & & \textbf{8 vCPUs, 30 GB RAM} \\
    \bottomrule
  \end{tabular}
\end{table}

\begin{figure}[H]
  \centering
  \includegraphics[width=0.8\linewidth]{../img/standard-cluster-images/cluster1_vm_instances_configuration.png}
  \caption{Configuración de instancias VM del Cluster 1 en Dataproc.}
  \label{fig:cluster1-vms}
\end{figure}

\paragraph{Cluster 2: Configuración high-memory (n2-highmem).}
Cluster con perfil de alta memoria, optimizado para cargas de trabajo intensivas en memoria:

\begin{table}[H]
  \centering
  \caption{Configuración del Cluster 2 (n2-highmem-4w).}
  \label{tab:cluster2-config}
  \scriptsize
  \begin{tabular}{@{}lll@{}}
    \toprule
    Componente & Tipo de Máquina & Recursos \\
    \midrule
    Master & n2-highmem-4 & 4 vCPUs, 32 GB RAM \\
    Workers (4x) & n2-highmem-2 & 2 vCPUs, 16 GB RAM (cada uno) \\
    \midrule
    \textbf{Total} & & \textbf{12 vCPUs, 96 GB RAM} \\
    \bottomrule
  \end{tabular}
\end{table}

\begin{figure}[H]
  \centering
  \includegraphics[width=0.8\linewidth]{../img/high-mem-images/cluster2_vm_instances_configuration.png}
  \caption{Configuración de instancias VM del Cluster 2 en Dataproc.}
  \label{fig:cluster2-vms}
\end{figure}

\paragraph{Infraestructura como código (Terraform).}
Los clusters se provisionan mediante módulos de Terraform con variables parametrizables:

\begin{verbatim}
# cluster1.tfvars
cluster_name        = "iowa-cluster-n1-std-3w"
master_machine_type = "n1-standard-2"
worker_machine_type = "n1-standard-2"
num_workers         = 3

# cluster2.tfvars
cluster_name        = "iowa-cluster-n2-hm-4w"
master_machine_type = "n2-highmem-4"
worker_machine_type = "n2-highmem-2"
num_workers         = 4
\end{verbatim}

\subsubsection{Lectura del dataset desde GCS mediante PySpark}

El script \texttt{gold\_transform.py} inicializa una sesión de Spark y lee los datos de la capa Bronze almacenados en formato Parquet:

\begin{verbatim}
BRONZE_PATH = f"gs://{BUCKET}/bronze/iowa_sales"
df = spark.read.parquet(BRONZE_PATH)
records_read = df.count()  # 32,816,143 registros
\end{verbatim}

PySpark distribuye automáticamente la lectura de los múltiples archivos Parquet entre los workers del cluster, aprovechando el paralelismo para optimizar el tiempo de carga.

\subsubsection{Aplicación de limpieza, filtrado y transformación}

El procesamiento de la capa Gold se divide en tres etapas principales:

\paragraph{1. Limpieza de datos.}
Se aplican filtros para eliminar registros con valores nulos o inconsistentes en campos críticos:

\begin{verbatim}
df_clean = df.filter(
    (F.col("sale_dollars").isNotNull()) & (F.col("sale_dollars") > 0)
    & (F.col("bottles_sold").isNotNull()) & (F.col("bottles_sold") > 0)
    & (F.col("volume_sold_liters").isNotNull()) 
    & (F.col("volume_sold_liters") > 0)
).dropDuplicates()
\end{verbatim}

\textbf{Resultado:} De 32,816,143 registros iniciales, se limpiaron 32,801,412 registros (99.96\% de retención), eliminando solo 14,731 registros (0.04\%) con datos inconsistentes.

\paragraph{2. Feature engineering.}
Se generan características derivadas para enriquecer el dataset y mejorar el potencial predictivo:

\begin{itemize}
  \item \texttt{day\_of\_week}: Día de la semana (1-7) extraído de la fecha
  \item \texttt{quarter}: Trimestre del año (1-4)
  \item \texttt{is\_weekend}: Indicador binario (1 si es fin de semana, 0 si no)
  \item \texttt{price\_per\_bottle}: Precio unitario calculado como \texttt{sale\_dollars / bottles\_sold}
  \item \texttt{volume\_per\_bottle}: Volumen unitario calculado como \texttt{volume\_sold\_liters / bottles\_sold}
\end{itemize}

\begin{verbatim}
df_features = (
    df_clean
    .withColumn("day_of_week", F.dayofweek("date"))
    .withColumn("quarter", F.quarter("date"))
    .withColumn("is_weekend", 
        F.when(F.dayofweek("date").isin([1, 7]), 1).otherwise(0))
    .withColumn("price_per_bottle", 
        F.col("sale_dollars") / F.col("bottles_sold"))
    .withColumn("volume_per_bottle", 
        F.col("volume_sold_liters") / F.col("bottles_sold"))
)
\end{verbatim}

\paragraph{3. Escritura particionada a capa Gold.}
Los datos transformados se escriben en formato Parquet con particionamiento por año y mes para optimizar consultas futuras:

\begin{verbatim}
GOLD_PATH = f"gs://{BUCKET}/gold_{CLUSTER_NAME}/iowa_sales"
df_features.write.mode("overwrite")
    .partitionBy("year", "month")
    .parquet(GOLD_PATH)
\end{verbatim}

\begin{figure}[H]
  \centering
  \includegraphics[width=0.8\linewidth]{../img/cloud-storage-images/gcs_gold_cluster2_year_partitions.png}
  \caption{Estructura particionada por año en la capa Gold (Cluster 2).}
  \label{fig:gold-partitions}
\end{figure}

\subsubsection{Monitoreo de ejecución}

Durante la ejecución de los jobs, se monitorearon métricas de recursos y tiempos mediante la interfaz de Spark History Server y YARN:

\begin{figure}[H]
  \centering
  \includegraphics[width=0.8\linewidth]{../img/standard-cluster-images/cluster1_history_server_job_summary.png}
  \caption{Resumen del job en Spark History Server (Cluster 1).}
  \label{fig:cluster1-history}
\end{figure}

\begin{figure}[H]
  \centering
  \includegraphics[width=0.8\linewidth]{../img/high-mem-images/cluster2_history_server_job_summary.png}
  \caption{Resumen del job en Spark History Server (Cluster 2).}
  \label{fig:cluster2-history}
\end{figure}

\begin{figure}[H]
  \centering
  \includegraphics[width=0.8\linewidth]{../img/standard-cluster-images/cluster1_monitoring_cpu_memory.png}
  \caption{Monitoreo de CPU y memoria durante ejecución (Cluster 1).}
  \label{fig:cluster1-monitoring}
\end{figure}

\begin{figure}[H]
  \centering
  \includegraphics[width=0.8\linewidth]{../img/high-mem-images/cluster2_monitoring_cpu_memory.png}
  \caption{Monitoreo de CPU y memoria durante ejecución (Cluster 2).}
  \label{fig:cluster2-monitoring}
\end{figure}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Modelado predictivo en PySpark}

\subsubsection{Modelo seleccionado}
Se seleccionó un modelo de \textbf{Regresión Lineal (Linear Regression)} utilizando la librería \texttt{pyspark.ml.regression}. Este algoritmo fue elegido por su eficiencia computacional en escenarios distribuidos, interpretabilidad directa de coeficientes y adecuación para predecir una variable continua (\texttt{sale\_dollars}) con relaciones lineales fuertes observadas en el EDA (ej. precio y volumen).

\subsubsection{Entrenamiento del modelo}
El entrenamiento se realizó sobre el dataset completo (32M+ registros) utilizando \texttt{VectorAssembler} para consolidar las características numéricas y temporales. Se empleó una división aleatoria de datos (80\% entrenamiento, 20\% prueba) con semilla fija (\texttt{seed=42}) para garantizar la comparabilidad entre las ejecuciones en diferentes clusters.

\subsubsection{Métricas de evaluación}
Las métricas obtenidas son consistentes en ambos clusters debido al uso de la misma semilla aleatoria, confirmando la determinismo del proceso de entrenamiento distribuido:

\begin{table}[H]
  \centering
  \caption{Métricas de evaluación del modelo (Linear Regression).}
  \label{tab:model-metrics}
  \scriptsize
  \begin{tabular}{@{}lcc@{}}
    \toprule
    Métrica & Cluster 1 & Cluster 2 \\
    \midrule
    R² & 0.7552 & 0.7552 \\
    RMSE & 258.01 & 258.01 \\
    MAE & 58.17 & 58.17 \\
    \bottomrule
  \end{tabular}
\end{table}

El \textbf{R² de 0.7552} indica que el modelo explica aproximadamente el 75.5\% de la variabilidad en las ventas, un resultado sólido considerando la simplicidad del modelo y el uso exclusivo de variables numéricas y temporales básicas.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Evaluación comparativa entre configuraciones de cluster}

\subsubsection{Comparación en Data Engineering (ETL y Transformación)}

\paragraph{Métricas de tiempo de ejecución por etapa.}

La fase de transformación Gold se ejecutó en ambos clusters con resultados significativamente diferentes:

\begin{table}[H]
  \centering
  \caption{Comparativa de tiempos de ejecución - Fase Gold (Data Engineering).}
  \label{tab:time-comparison-de}
  \scriptsize
  \begin{tabular}{@{}lccc@{}}
    \toprule
    Etapa & Cluster 1 & Cluster 2 & Mejora \\
    \midrule
    Inicialización Spark & 18.73s & 9.68s & 48.3\% más rápido \\
    Lectura Bronze & 47.60s & 32.74s & 31.2\% más rápido \\
    Limpieza de datos & 183.98s & 94.33s & 48.7\% más rápido \\
    Feature engineering & 150.98s & 69.07s & 54.2\% más rápido \\
    Escritura Gold particionada & 1305.39s & 869.92s & 33.4\% más rápido \\
    \midrule
    \textbf{Total Gold Phase} & \textbf{1706.68s (28.44 min)} & \textbf{1075.75s (17.93 min)} & \textbf{36.8\% más rápido} \\
    \midrule
    \textbf{Pipeline completo} & \textbf{1715.19s (28.59 min)} & \textbf{1084.26s (18.07 min)} & \textbf{36.8\% más rápido} \\
    \bottomrule
  \end{tabular}
\end{table}

\paragraph{Análisis de performance por etapa.}

\begin{itemize}
  \item \textbf{Inicialización Spark (48.3\% mejora):} El Cluster 2 con mayor memoria (96 GB vs 30 GB) permite una inicialización más rápida del contexto de Spark y asignación de recursos.
  
  \item \textbf{Lectura Bronze (31.2\% mejora):} La lectura distribuida de archivos Parquet se beneficia del mayor número de workers (4 vs 3) y mayor memoria disponible para cacheo.
  
  \item \textbf{Limpieza de datos (48.7\% mejora):} Las operaciones de filtrado y deduplicación son intensivas en memoria. El perfil high-memory del Cluster 2 reduce significativamente los spills a disco.
  
  \item \textbf{Feature engineering (54.2\% mejora):} La etapa con mayor mejora relativa. Las transformaciones complejas (cálculos de columnas derivadas) se benefician enormemente de la mayor memoria disponible por worker.
  
  \item \textbf{Escritura Gold (33.4\% mejora):} El particionamiento por año/mes requiere shuffling intensivo. El Cluster 2 maneja mejor el shuffle con mayor memoria y más workers.
\end{itemize}

\begin{figure}[H]
  \centering
  \includegraphics[width=0.8\linewidth]{../img/standard-cluster-images/cluster1_stages_timing_breakdown.png}
  \caption{Desglose de tiempos por stage en Cluster 1.}
  \label{fig:cluster1-stages}
\end{figure}

\begin{figure}[H]
  \centering
  \includegraphics[width=0.8\linewidth]{../img/high-mem-images/cluster2_stages_timing_breakdown.png}
  \caption{Desglose de tiempos por stage en Cluster 2.}
  \label{fig:cluster2-stages}
\end{figure}

\paragraph{Análisis de latencia, paralelismo y escalabilidad.}

\begin{itemize}
  \item \textbf{Latencia:} El Cluster 2 reduce la latencia total en 630.93 segundos (10.52 minutos), representando una mejora del 36.8\%. Esta reducción es consistente en todas las etapas, indicando que el cuello de botella principal era la memoria disponible.

  \item \textbf{Paralelismo:} El Cluster 2 con 4 workers vs 3 del Cluster 1 permite mayor paralelización de tareas. Sin embargo, la mejora no es proporcional al 33\% adicional de workers, sino que se amplifica por la mayor memoria disponible (96 GB vs 30 GB = 3.2x más memoria).

  \item \textbf{Escalabilidad:} Los resultados demuestran que para datasets de 32M+ registros con transformaciones complejas, la memoria es el factor limitante más crítico que el número de cores. El Cluster 2 con perfil high-memory escala mejor que el Cluster 1 estándar.
\end{itemize}

\begin{figure}[H]
  \centering
  \includegraphics[width=0.8\linewidth]{../img/standard-cluster-images/cluster1_executors_resource_utilization.png}
  \caption{Utilización de recursos por executors en Cluster 1.}
  \label{fig:cluster1-executors}
\end{figure}

\begin{figure}[H]
  \centering
  \includegraphics[width=0.8\linewidth]{../img/high-mem-images/cluster2_executors_resource_utilization.png}
  \caption{Utilización de recursos por executors en Cluster 2.}
  \label{fig:cluster2-executors}
\end{figure}

\paragraph{Análisis de costos.}

\begin{itemize}
  \item \textbf{Conclusión de costos:} El Cluster 2 cuesta 27\% más por job pero entrega 36.8\% de mejora en tiempo. Este trade-off es favorable para cargas de trabajo time-sensitive o cuando se ejecutan múltiples jobs diarios.
\end{itemize}

\begin{table}[H]
  \centering
  \caption{Análisis de costos por configuración de cluster.}
  \label{tab:cost-analysis}
  \scriptsize
  \begin{tabular}{@{}lcc@{}}
    \toprule
    Concepto & Cluster 1 & Cluster 2 \\
    \midrule
    Costo por hora (Compute Engine) & \$0.3800/hr & \$0.8040/hr \\
    Costo por hora (Dataproc) & \$0.0800/hr & \$0.1200/hr \\
    \textbf{Costo total por hora} & \textbf{\$0.4600/hr} & \textbf{\$0.9240/hr} \\
    \midrule
    Tiempo de ejecución & 28.59 min & 18.07 min \\
    \textbf{Costo por job} & \textbf{\$0.219} & \textbf{\$0.278} \\
    \midrule
    Diferencia de costo & \multicolumn{2}{c}{\$0.059 más (27\% premium)} \\
    Mejora de tiempo & \multicolumn{2}{c}{36.8\% más rápido} \\
    \bottomrule
  \end{tabular}
\end{table}



\subsubsection{Comparación en Data Science (Modelado ML)}
 
 \paragraph{Métricas de tiempo de entrenamiento.}
 
 Se observó una reducción significativa en el tiempo total de la fase de Machine Learning al utilizar el Cluster 2 (High Memory). La mayor disponibilidad de RAM permitió que las etapas intensivas en cómputo iterativo, como el ajuste del modelo (\texttt{fit}), se ejecutaran mucho más rápido al minimizar la serialización y el spilling a disco.
 
  \begin{table}[H]
    \centering
    \caption{Comparativa de tiempos de entrenamiento ML.}
    \label{tab:time-comparison-ml}
    \scriptsize
    \begin{tabular}{@{}lccc@{}}
      \toprule
      Etapa & Cluster 1 & Cluster 2 & Mejora \\
      \midrule
      Spark Init      & 11.33s   & 8.79s    & 22.4\% Más Rápido \\
      Lectura Gold    & 14.27s   & 11.39s   & 20.2\% Más Rápido \\
      Feature Prep    & 2.47s    & 1.33s    & 46.2\% Más Rápido \\
      Model Training  & 965.96s  & 690.91s  & 28.5\% Más Rápido \\
      Evaluation      & 1287.01s & 801.14s  & 37.8\% Más Rápido \\
      \midrule
      \textbf{Total ML Phase} 
        & \textbf{3130.10s (52.17 min)} 
        & \textbf{2048.00s (34.13 min)} 
        & \textbf{34.6\% Más Rápido} \\
      \bottomrule
    \end{tabular}
  \end{table}
 
 \paragraph{Análisis de los resultados de tiempo.}
 
 \begin{itemize}
  \item \textbf{Entrenamiento del Modelo (28.5\% mejora):}  
  Aunque la Regresión Lineal distribuida requiere múltiples pasadas sobre los datos, la reducción de tiempo proviene de una mejor gestión del shuffle y menor spill a disco. El Cluster 2, con mayor memoria y mejores CPUs (N2), pudo mantener más datos en memoria y paralelizar de forma más eficiente el cálculo de gradientes.
  \item \textbf{Feature Preparation (46.2\% mejora):}  
  La etapa de ensamblado de características (\texttt{VectorAssembler}) se beneficia notablemente del aumento en paralelismo y memoria. Al reducir el costo de serialización y evitar recomputaciones, el Cluster 2 completa estas transformaciones casi al doble de velocidad.
  \item \textbf{Evaluación (37.8\% mejora):}  
  La fase de evaluación —que incluye generar predicciones sobre 6.5M de registros y calcular métricas— mejora considerablemente. Esto indica que esta etapa sí es intensiva en CPU y shuffle, no solo en I/O. El hardware del Cluster 2 reduce significativamente el tiempo de ejecución de estas acciones distribuidas.
\end{itemize}
 
 \paragraph{Análisis de escalabilidad en ML.}
 
 La configuración del cluster impactó directamente en la eficiencia del entrenamiento:
 
\begin{itemize}
  \item \textbf{Eficiencia de Memoria:} El Cluster 1 operó cerca de sus límites de memoria, lo que probablemente causó overhead por Garbage Collection (GC) excesivo durante el entrenamiento. El Cluster 2, con holgura de memoria, evitó estas pausas.
  \item \textbf{Throughput:} El Cluster 2 procesó el entrenamiento a una tasa efectiva de ~38,000 registros/segundo, comparado con ~20,000 registros/segundo del Cluster 1.
\end{itemize}

\begin{figure}[H]
  \centering
  \includegraphics[width=0.8\linewidth]{../img/standard-cluster-images/ml-c1-simple-100pt.png}
  \caption{Monitoreo de de recursos durante el entrenamiento del modelo en el Cluster 1.}
  \label{fig:ml-cluster1-monitoring}
\end{figure}

\begin{figure}[H]
  \centering
  \includegraphics[width=0.8\linewidth]{../img/high-mem-images/ml-c2-lr-100pt.png}
  \caption{Monitoreo de de recursos durante el entrenamiento del modelo en el Cluster 2.}
  \label{fig:ml-cluster2-monitoring}
\end{figure}

\begin{figure}[H]
  \centering
  \includegraphics[width=0.8\linewidth]{../img/high-mem-images/ml-cluster2_history_server_job_summary.png}
  \caption{Resumen del job ML en Spark History Server (Cluster 2).}
  \label{fig:ml-cluster2-history}
\end{figure}

\begin{figure}[H]
  \centering
  \includegraphics[width=0.8\linewidth]{../img/high-mem-images/ml-cluster2_jobs_event_timeline.png}
  \caption{Timeline de eventos del job ML (Cluster 2).}
  \label{fig:ml-cluster2-timeline}
\end{figure}

\begin{figure}[H]
  \centering
  \includegraphics[width=0.8\linewidth]{../img/high-mem-images/ml-cluster2_stages_timing_breakdown.png}
  \caption{Desglose de tiempos por stage en el job ML (Cluster 2).}
  \label{fig:ml-cluster2-stages}
\end{figure}

\begin{figure}[H]
  \centering
  \includegraphics[width=0.8\linewidth]{../img/high-mem-images/ml-cluster2_executors_resource_utilization.png}
  \caption{Utilización de recursos de executors durante el job ML (Cluster 2).}
  \label{fig:ml-cluster2-executors}
\end{figure}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% 4. RESULTADOS Y ANÁLISIS
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Métricas, gráficas y análisis de resultados}

\subsection{Interpretación de resultados}
Los resultados obtenidos validan la eficacia del modelo de Regresión Lineal distribuido para predecir las ventas. El R² de 0.75 indica una correlación fuerte positiva entre las características seleccionadas y la variable objetivo:

\begin{itemize}
    \item \textbf{Costo y Volumen:} Las variables \texttt{price\_per\_bottle} y \texttt{bottles\_sold} son, como se esperaba, los predictores más fuertes. La relación matemática inherente ($Ingreso = Precio \times Cantidad$) es capturada eficazmente por el modelo lineal.
    \item \textbf{Estacionalidad:} Las características temporales (\texttt{quarter}, \texttt{is\_weekend}) permitieron al modelo ajustar por variaciones estacionales, mejorando la precisión sobre un modelo base que solo considerara precio y volumen.
    \item \textbf{Escala Masiva:} El modelo logró generalizar patrones a través de 13 años de historia sin caer en over-fitting obvio (evaluado en 6.5M de registros no vistos), demostrando robustez.
\end{itemize}

\subsection{Justificación del muestreo}

En este proyecto se tomó la decisión de \textbf{no aplicar muestreo} y trabajar con el \textbf{dataset completo} de 32,816,143 registros. Esta decisión se fundamenta en principios de MLOps y mejores prácticas de ciencia de datos a gran escala:

\paragraph{Razones técnicas y de negocio:}

\begin{enumerate}
  \item \textbf{Capacidad de infraestructura distribuida:} El uso de Dataproc con PySpark permite procesar eficientemente el volumen completo de datos mediante paralelización. El muestreo habría subutilizado la capacidad del cluster y no habría justificado el costo de la infraestructura distribuida.
  
  \item \textbf{Representatividad y generalización:} Al utilizar el dataset completo, se garantiza que el modelo capture todos los patrones, estacionalidades y variaciones presentes en 13.8 años de datos históricos. Un muestreo podría introducir sesgos al excluir eventos raros pero importantes (e.g., ventas atípicas, productos de baja frecuencia, tiendas pequeñas).
  
  \item \textbf{Cobertura de alta cardinalidad:} Con 15,183 productos únicos, 3,337 tiendas y 504 ciudades, un muestreo podría excluir combinaciones importantes de características que son críticas para la predicción en segmentos específicos del negocio.
  
  \item \textbf{Validación de escalabilidad:} Uno de los objetivos del proyecto es demostrar la capacidad de procesamiento distribuido en entornos de datos masivos. Trabajar con el dataset completo valida que el pipeline puede manejar volúmenes reales de producción sin degradación de performance.
  
  \item \textbf{Reproducibilidad y trazabilidad:} Al no aplicar muestreo aleatorio, se elimina una fuente de variabilidad en los resultados. Cada ejecución del pipeline procesa exactamente los mismos datos, facilitando la reproducibilidad y el debugging.
  
  \item \textbf{Optimización de costos:} Aunque procesar el dataset completo consume más recursos computacionales, el tiempo total de ejecución (17.93 minutos en Cluster 2) es aceptable y el costo incremental es marginal comparado con el valor de tener un modelo entrenado sobre datos completos.
\end{enumerate}

\paragraph{Estrategia de validación sin muestreo:}

En lugar de muestreo para reducir volumen, se implementaron las siguientes estrategias:

\begin{itemize}
  \item \textbf{Particionamiento temporal:} Los datos se particionan por año y mes, permitiendo procesamiento incremental y consultas eficientes sobre ventanas temporales específicas.
  
  \item \textbf{Limpieza selectiva:} Se eliminaron únicamente registros con valores nulos o inconsistentes (0.04\% del total), preservando el 99.96\% de los datos válidos.
  
  \item \textbf{Feature engineering distribuido:} Las transformaciones se ejecutan en paralelo sobre el dataset completo, aprovechando la arquitectura distribuida de Spark.
  
  \item \textbf{Evaluación comparativa de clusters:} Se validó que ambas configuraciones de cluster pueden procesar el volumen completo, con el Cluster 2 (high-memory) completando en 17.93 minutos vs 28.44 minutos del Cluster 1.
\end{itemize}

\subsection{Evaluación del desempeño del modelo}
El análisis crítico del desempeño revela:
\begin{enumerate}
    \item \textbf{Precisión (R² 0.75):} Aceptable para un modelo base de regresión. Sin embargo, deja un 25\% de varianza sin explicar. Esto sugiere que existen factores no lineales o interacciones complejas (ej. preferencias del consumidor por tienda/barrio específica) que un modelo lineal simple no es capaz de capturar.
    \item \textbf{Error Absoluto (MAE $\sim\$58$):} En promedio, el modelo presenta un error de aproximadamente \$58 por transacción. Este nivel de error es adecuado para el contexto mayorista, donde las ventas suelen involucrar volúmenes y montos altos, por lo que la desviación relativa es baja. Sin embargo, si el modelo se aplicara a transacciones minoristas de menor valor, este mismo error absoluto podría representar una proporción significativa del monto total, disminuyendo su utilidad en ese segmento.
    \item \textbf{Limitaciones Lineales:} Intentar modelos más complejos (como Gradient Boosted Trees) en este volumen de datos demostró ser computacionalmente prohibitivo con los recursos actuales (OOM errors en Cluster 1), resaltando el trade-off entre complejidad del modelo y viabilidad operativa en Big Data.
\end{enumerate}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% 5. ANÁLISIS CRÍTICO
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Análisis crítico del enfoque}

\subsection{Ventajas del enfoque elegido}

\begin{enumerate}
  \item \textbf{Escalabilidad horizontal demostrada:} El enfoque de procesamiento distribuido con PySpark en Dataproc permite escalar horizontalmente agregando más workers al cluster. Los resultados muestran que el Cluster 2 con 4 workers y mayor memoria procesó 32M+ registros 36.8\% más rápido que el Cluster 1 con 3 workers, validando la capacidad de escalar para volúmenes aún mayores sin cambios arquitectónicos.
  
  \item \textbf{Arquitectura medallion reproducible:} La implementación de capas Bronze y Gold con infraestructura como código (Terraform) garantiza reproducibilidad completa del pipeline. Cualquier miembro del equipo puede provisionar la infraestructura exacta y ejecutar el mismo flujo de datos, facilitando colaboración y debugging.
  
  \item \textbf{Separación de responsabilidades (Data Engineering vs Data Science):} La arquitectura separa claramente la fase de ETL/transformación (Data Engineering en capas Bronze/Gold) de la fase de modelado (Data Science sobre Gold layer). Esto permite que equipos especializados trabajen en paralelo y optimicen cada fase independientemente.
  
  \item \textbf{Optimización de costos mediante comparación empírica:} Al evaluar dos configuraciones de cluster con métricas detalladas de tiempo y costo, se puede tomar decisiones informadas sobre el trade-off costo-performance. El análisis mostró que el Cluster 2 cuesta 27\% más pero entrega 36.8\% de mejora en tiempo, permitiendo elegir la configuración óptima según prioridades del negocio.
  
  \item \textbf{Formato columnar optimizado (Parquet):} El uso de Parquet con particionamiento por año/mes reduce significativamente el tiempo de lectura y el costo de consultas. Este formato es usado para data lakes y permite compresión eficiente sin sacrificar velocidad de acceso.
  
  \item \textbf{Determinismo en Resultados:} Gracias a la fijación de semillas (\texttt{seed=42}) en operaciones distribuidas, logramos replicar exactamente las métricas (R²) en diferentes infraestructuras, un requisito crítico para auditoría de modelos.
\end{enumerate}

\subsection{Limitaciones del enfoque elegido}

\begin{enumerate}
  \item \textbf{Procesamiento batch sin capacidad de tiempo real:} El pipeline actual opera en modo batch con ejecución manual o programada. No existe capacidad de procesamiento en streaming o near-real-time, lo que limita su aplicabilidad para casos de uso que requieren predicciones inmediatas (e.g., detección de fraude en tiempo real, recomendaciones instantáneas). La latencia mínima del pipeline completo es de ~18 minutos (Cluster 2), inadecuada para escenarios time-sensitive.
  
  \item \textbf{Ausencia de entrenamiento incremental/online:} El modelo requiere reentrenamiento completo sobre todo el dataset cada vez que se actualice. No existe mecanismo de online learning o entrenamiento incremental que permita actualizar el modelo con nuevos datos sin reprocesar el histórico completo. Esto incrementa costos y tiempo de actualización del modelo en producción.
  
  \item \textbf{Dependencia de infraestructura cloud específica (GCP):} La arquitectura está fuertemente acoplada a servicios de Google Cloud Platform (BigQuery, Cloud Run, Dataproc, GCS). Migrar a otro proveedor cloud (AWS, Azure) requeriría reescribir componentes significativos del pipeline, limitando la portabilidad y aumentando el vendor lock-in.
  \item \textbf{Complejidad vs. Recursos:} El intento fallido de entrenar modelos más complejos (como GBT) en el Cluster 1 evidenció que, bajo las restricciones de presupuesto y los límites del crédito gratuito disponible, no fue viable escalar a una infraestructura mayor. En este contexto, se optó por algoritmos más simples (como Linear Regression) debido a las limitaciones de recursos. Con recursos de cómputo más amplios, modelos más complejos podrían entrenarse adecuadamente.
\end{enumerate}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% 6. CONCLUSIONES
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Conclusiones}

Este proyecto demostró exitosamente la implementación de un pipeline de datos end-to-end sobre Google Cloud Platform, capaz de ingerir, procesar y modelar más de 32 millones de registros de ventas de licores.

\begin{enumerate}
    \item \textbf{Infraestructura Correcta para Big Data:} Se validó que para datasets de esta magnitud y alta dimensionalidad, el uso de Spark Clusters con perfil de memoria optimizado (n2-highmem) es superior (35-46\% más rápido) a clusters de propósito general, justificando la inversión adicional por hora.
    \item \textbf{Valor del Modelo:} Con un R² de 0.75, el modelo lineal provee una línea base sólida para predicción de ingresos, útil para planeación de inventarios a nivel macro.
    \item \textbf{Automatización:} La integración de Terraform y Scripts Python parametrizados permitió comparar escenarios (Cluster 1 vs Cluster 2) de manera científica y controlada, cumpliendo con los estándares de reproducibilidad exigidos en ingeniería de datos moderna.
\end{enumerate}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% 7. CÓDIGO Y REPOSITORIO
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Código utilizado}

\subsection{Repositorio de código fuente}
\url{https://github.com/LuisGuillen03/ML-BigData}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% REFERENCIAS
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Referencias}

\begin{itemize}
  \item Google LLC (s. f.). Google Cloud Console. \url{https://console.cloud.google.com/}
  \item Google Cloud. (2024). Crea un clúster de Dataproc con la consola de Google Cloud. \url{https://cloud.google.com/dataproc/docs/quickstarts/create-cluster-console?hl=es-419}
  \item Google Cloud. (2024). Dataproc Pricing. \url{https://cloud.google.com/dataproc/pricing}
  \item Google Cloud. (2024). Compute Engine Pricing. \url{https://cloud.google.com/compute/all-pricing}
  \item Google Cloud. (2024). Cloud Run Pricing. \url{https://cloud.google.com/run/pricing}
  \item Google Cloud. (2024). Deploy a Cloud Run job. \url{https://cloud.google.com/run/docs/create-jobs}
  \item BigQuery Public Data. Iowa Liquor Sales. \url{https://console.cloud.google.com/marketplace/product/iowa-department-of-commerce/iowa-liquor-sales}
\end{itemize}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\end{document}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
